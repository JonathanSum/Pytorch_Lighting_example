{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimCLR1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOMYhc/MbitwDA1lkl7J/4H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonathanSum/Pytorch_Lighting_example/blob/master/SimCLR1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNB1HoJnw5Ts",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "250f04be-4b97-428e-cbbb-276c2e754149"
      },
      "source": [
        "pip install pytorch-lightning-bolts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-lightning-bolts\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/27/5376b533536bf095f0e2d10c7fc5629b1ee324d8e0e41edc942b3326b6bd/pytorch_lightning_bolts-0.1.1-py3-none-any.whl (174kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 20.1MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 40kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 51kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 61kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 71kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 81kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 92kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 102kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 112kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 122kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 133kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 143kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 153kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 163kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning-bolts) (1.6.0+cu101)\n",
            "Requirement already satisfied: torchvision>=0.7 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning-bolts) (0.7.0+cu101)\n",
            "Collecting scikit-learn>=0.23\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 15.4MB/s \n",
            "\u001b[?25hCollecting trains>=0.14.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/b2/c4a73d57867b74c0693e62acb93852e614c5a15925b8c958fcb00308e657/trains-0.16.1-py2.py3-none-any.whl (778kB)\n",
            "\u001b[K     |████████████████████████████████| 788kB 38.9MB/s \n",
            "\u001b[?25hCollecting pytorch-lightning>=0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/af/2f10c8ee22d7a05fe8c9be58ad5c55b71ab4dd895b44f0156bfd5535a708/pytorch_lightning-0.9.0-py3-none-any.whl (408kB)\n",
            "\u001b[K     |████████████████████████████████| 409kB 54.9MB/s \n",
            "\u001b[?25hCollecting test-tube>=0.7.5\n",
            "  Downloading https://files.pythonhosted.org/packages/91/f0/5c32f2fbd824f32354f7f4632c957163071597bb2c6a4105f507bc9af7c0/test_tube-0.7.5.tar.gz\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning-bolts) (4.1.2.30)\n",
            "Requirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning-bolts) (0.17.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6->pytorch-lightning-bolts) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.6->pytorch-lightning-bolts) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.7->pytorch-lightning-bolts) (7.0.0)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.23->pytorch-lightning-bolts) (0.16.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.23->pytorch-lightning-bolts) (1.4.1)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (1.15.0)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (2.23.0)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (3.13)\n",
            "Requirement already satisfied: plotly>=3.9.0 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (4.4.1)\n",
            "Requirement already satisfied: tqdm>=4.19.5 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (4.41.1)\n",
            "Collecting pyjwt>=1.6.4\n",
            "  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: jsonschema>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (2.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (2.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (2.4.7)\n",
            "Collecting funcsigs>=1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
            "Collecting pathlib2>=2.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/45/9c82d3666af4ef9f221cbb954e1d77ddbb513faf552aea6df5f37f1a4859/pathlib2-2.3.5-py2.py3-none-any.whl\n",
            "Collecting furl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/9f/c7/e9dc30914bf048bcd06284bb93d9650d318ecac8668b684fc41e975558ff/furl-2.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=18.0 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (20.1.0)\n",
            "Requirement already satisfied: psutil>=3.4.2 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (5.4.8)\n",
            "Collecting requests-file>=1.4.2\n",
            "  Downloading https://files.pythonhosted.org/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl\n",
            "Collecting humanfriendly>=2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/2d/2f1b0a780b8c948c06c74c8c80e68ac354da52397ba432a1c5ac1923c3af/humanfriendly-8.2-py2.py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 12.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (1.24.3)\n",
            "Collecting tensorboard==2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/f5/d75a6f7935e4a4870d85770bc9976b12e7024fbceb83a1a6bc50e6deb7c4/tensorboard-2.2.0-py3-none-any.whl (2.8MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8MB 49.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning>=0.9.0->pytorch-lightning-bolts) (20.4)\n",
            "Requirement already satisfied: pandas>=0.20.3 in /usr/local/lib/python3.6/dist-packages (from test-tube>=0.7.5->pytorch-lightning-bolts) (1.0.5)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from test-tube>=0.7.5->pytorch-lightning-bolts) (2.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.17.2->pytorch-lightning-bolts) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.17.2->pytorch-lightning-bolts) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->trains>=0.14.1->pytorch-lightning-bolts) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->trains>=0.14.1->pytorch-lightning-bolts) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->trains>=0.14.1->pytorch-lightning-bolts) (2020.6.20)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=3.9.0->trains>=0.14.1->pytorch-lightning-bolts) (1.3.3)\n",
            "Collecting orderedmultidict>=1.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/04/16/5e95c70bda8fe6ea715005c0db8e602400bdba50ae3c72cb380eba551289/orderedmultidict-1.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.2.0->pytorch-lightning>=0.9.0->pytorch-lightning-bolts) (1.31.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.2.0->pytorch-lightning>=0.9.0->pytorch-lightning-bolts) (3.2.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.2.0->pytorch-lightning>=0.9.0->pytorch-lightning-bolts) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.2.0->pytorch-lightning>=0.9.0->pytorch-lightning-bolts) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.2.0->pytorch-lightning>=0.9.0->pytorch-lightning-bolts) (0.35.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.2.0->pytorch-lightning>=0.9.0->pytorch-lightning-bolts) (3.12.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.2.0->pytorch-lightning>=0.9.0->pytorch-lightning-bolts) (49.6.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.2.0->pytorch-lightning>=0.9.0->pytorch-lightning-bolts) (0.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.2.0->pytorch-lightning>=0.9.0->pytorch-lightning-bolts) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard==2.2.0->pytorch-lightning>=0.9.0->pytorch-lightning-bolts) (1.17.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.3->test-tube>=0.7.5->pytorch-lightning-bolts) (2018.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard==2.2.0->pytorch-lightning>=0.9.0->pytorch-lightning-bolts) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.2.0->pytorch-lightning>=0.9.0->pytorch-lightning-bolts) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.2.0->pytorch-lightning>=0.9.0->pytorch-lightning-bolts) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.2.0->pytorch-lightning>=0.9.0->pytorch-lightning-bolts) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.2.0->pytorch-lightning>=0.9.0->pytorch-lightning-bolts) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard==2.2.0->pytorch-lightning>=0.9.0->pytorch-lightning-bolts) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.2.0->pytorch-lightning>=0.9.0->pytorch-lightning-bolts) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard==2.2.0->pytorch-lightning>=0.9.0->pytorch-lightning-bolts) (0.4.8)\n",
            "Building wheels for collected packages: test-tube\n",
            "  Building wheel for test-tube (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for test-tube: filename=test_tube-0.7.5-cp36-none-any.whl size=25357 sha256=f71d8c45a1bccb87c0bedc65e6f245b6121e31ad857f42d152f9b890ad807324\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/52/96/c8b6f3c345cfd3284845ef50818c6996a5658006fe50e40e98\n",
            "Successfully built test-tube\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorboard<3,>=2.3.0, but you'll have tensorboard 2.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pytorch-lightning 0.9.0 has requirement future>=0.17.1, but you'll have future 0.16.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pytorch-lightning 0.9.0 has requirement PyYAML>=5.1, but you'll have pyyaml 3.13 which is incompatible.\u001b[0m\n",
            "Installing collected packages: threadpoolctl, scikit-learn, pyjwt, funcsigs, pathlib2, orderedmultidict, furl, requests-file, humanfriendly, trains, tensorboard, pytorch-lightning, test-tube, pytorch-lightning-bolts\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "Successfully installed funcsigs-1.0.2 furl-2.1.0 humanfriendly-8.2 orderedmultidict-1.0.1 pathlib2-2.3.5 pyjwt-1.7.1 pytorch-lightning-0.9.0 pytorch-lightning-bolts-0.1.1 requests-file-1.5.1 scikit-learn-0.23.2 tensorboard-2.2.0 test-tube-0.7.5 threadpoolctl-2.1.0 trains-0.16.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga8bU1yhzUgR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "364a19b2-fb6b-4812-807f-2c7755990969"
      },
      "source": [
        "pip install pytorch-lightning-bolts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-lightning-bolts in /usr/local/lib/python3.6/dist-packages (0.1.1)\n",
            "Requirement already satisfied: trains>=0.14.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning-bolts) (0.16.1)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning-bolts) (1.6.0+cu101)\n",
            "Requirement already satisfied: test-tube>=0.7.5 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning-bolts) (0.7.5)\n",
            "Requirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning-bolts) (0.17.2)\n",
            "Requirement already satisfied: pytorch-lightning>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning-bolts) (0.9.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning-bolts) (4.1.2.30)\n",
            "Requirement already satisfied: torchvision>=0.7 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning-bolts) (0.7.0+cu101)\n",
            "Requirement already satisfied: scikit-learn>=0.23 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning-bolts) (0.23.2)\n",
            "Requirement already satisfied: pathlib2>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (2.3.5)\n",
            "Requirement already satisfied: jsonschema>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (2.6.0)\n",
            "Requirement already satisfied: Pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (7.0.0)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (0.16.0)\n",
            "Requirement already satisfied: tqdm>=4.19.5 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (1.18.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (2.8.1)\n",
            "Requirement already satisfied: attrs>=18.0 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (20.1.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (1.15.0)\n",
            "Requirement already satisfied: plotly>=3.9.0 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (4.4.1)\n",
            "Requirement already satisfied: humanfriendly>=2.1 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (8.2)\n",
            "Requirement already satisfied: furl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (2.1.0)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (2.23.0)\n",
            "Requirement already satisfied: psutil>=3.4.2 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (5.4.8)\n",
            "Requirement already satisfied: funcsigs>=1.0 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (1.0.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (1.24.3)\n",
            "Requirement already satisfied: pyjwt>=1.6.4 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (1.7.1)\n",
            "Requirement already satisfied: requests-file>=1.4.2 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (1.5.1)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from trains>=0.14.1->pytorch-lightning-bolts) (3.13)\n",
            "Requirement already satisfied: pandas>=0.20.3 in /usr/local/lib/python3.6/dist-packages (from test-tube>=0.7.5->pytorch-lightning-bolts) (1.0.5)\n",
            "Requirement already satisfied: tensorboard>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from test-tube>=0.7.5->pytorch-lightning-bolts) (2.2.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from test-tube>=0.7.5->pytorch-lightning-bolts) (2.4.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym>=0.17.2->pytorch-lightning-bolts) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.17.2->pytorch-lightning-bolts) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.17.2->pytorch-lightning-bolts) (1.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning>=0.9.0->pytorch-lightning-bolts) (20.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.23->pytorch-lightning-bolts) (0.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.23->pytorch-lightning-bolts) (2.1.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=3.9.0->trains>=0.14.1->pytorch-lightning-bolts) (1.3.3)\n",
            "Requirement already satisfied: orderedmultidict>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from furl>=2.0.0->trains>=0.14.1->pytorch-lightning-bolts) (1.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->trains>=0.14.1->pytorch-lightning-bolts) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->trains>=0.14.1->pytorch-lightning-bolts) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->trains>=0.14.1->pytorch-lightning-bolts) (2.10)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.3->test-tube>=0.7.5->pytorch-lightning-bolts) (2018.9)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.15.0->test-tube>=0.7.5->pytorch-lightning-bolts) (3.2.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.15.0->test-tube>=0.7.5->pytorch-lightning-bolts) (0.8.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.15.0->test-tube>=0.7.5->pytorch-lightning-bolts) (1.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.15.0->test-tube>=0.7.5->pytorch-lightning-bolts) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.15.0->test-tube>=0.7.5->pytorch-lightning-bolts) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.15.0->test-tube>=0.7.5->pytorch-lightning-bolts) (49.6.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.15.0->test-tube>=0.7.5->pytorch-lightning-bolts) (0.35.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.15.0->test-tube>=0.7.5->pytorch-lightning-bolts) (1.31.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.15.0->test-tube>=0.7.5->pytorch-lightning-bolts) (1.17.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.15.0->test-tube>=0.7.5->pytorch-lightning-bolts) (3.12.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=1.15.0->test-tube>=0.7.5->pytorch-lightning-bolts) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15.0->test-tube>=0.7.5->pytorch-lightning-bolts) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15.0->test-tube>=0.7.5->pytorch-lightning-bolts) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15.0->test-tube>=0.7.5->pytorch-lightning-bolts) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15.0->test-tube>=0.7.5->pytorch-lightning-bolts) (4.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.15.0->test-tube>=0.7.5->pytorch-lightning-bolts) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15.0->test-tube>=0.7.5->pytorch-lightning-bolts) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.15.0->test-tube>=0.7.5->pytorch-lightning-bolts) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4YjeNd0T1K2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim import Adam"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPaud5Tpw-Fw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from typing import Optional\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.callbacks import LearningRateLogger\n",
        "\n",
        "from pl_bolts.models.self_supervised.resnets import resnet50\n",
        "from pl_bolts.optimizers.lr_scheduler import LinearWarmupCosineAnnealingLR\n",
        "from pl_bolts.datamodules import CIFAR10DataModule, STL10DataModule, ImagenetDataModule\n",
        "from pl_bolts.metrics import mean, accuracy\n",
        "\n",
        "from pl_bolts.models.self_supervised.evaluator import Flatten\n",
        "from pl_bolts.transforms.dataset_normalizations import cifar10_normalization, stl10_normalization\n",
        "from pl_bolts.transforms.dataset_normalizations import imagenet_normalization\n",
        "from pl_bolts.optimizers.lars_scheduling import LARSWrapper\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biiwuxrETebW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GaussianBlur(object):\n",
        "    #implements Gaussian blur as described in the SimCLR paper\n",
        "    def __init__(self, kernel_size, p=0.5, min=0.1, max=2.0):\n",
        "        self.min = min\n",
        "        self.max = max\n",
        "\n",
        "        #kernel size is set to be 10% of the image height/width\n",
        "        self.kernel_size = kernel_size\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        sample = np.array(sample)\n",
        "\n",
        "        # blur the image with a 50% chance\n",
        "        prob = np.random.random_sample()\n",
        "\n",
        "        if prop < self.p:\n",
        "            sigma = (self.max - self.min) * np.random.random_sample() + self.min\n",
        "            sample = cv2.GaussianBlur(sample, (self.kernel_size, self.kernel_size), sigma)\n",
        "\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHhtzBDU-wFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class SimCLRTrainDataTransform(object):\n",
        "#     def __init__(\n",
        "#         self,\n",
        "#         input_height: int = 224,\n",
        "#         gaussian_blur: bool = False,\n",
        "#         jitter_strength: float = 1.,\n",
        "#         normalize: Optional[transforms.Normalize] = None\n",
        "#     ) -> None:\n",
        "\n",
        "#         self.jitter_strength = jitter_strength\n",
        "#         self.input_height = input_height\n",
        "#         self.gaussian_blur = gaussian_blur\n",
        "#         self.normalize = normalize\n",
        "\n",
        "#         self.color_jitter = transforms.ColorJitter(\n",
        "#             0.8 * self.jitter_strength,\n",
        "#             0.8 * self.jitter_strength,\n",
        "#             0.8 * self.jitter_strength,\n",
        "#             0.2 * self.jitter_strength\n",
        "#         )\n",
        "\n",
        "#         data_transforms = [\n",
        "#             transforms.RandomResizedCrop(size=self.input_height),\n",
        "#             transforms.RandomHorizontalFlip(p=0.5),\n",
        "#             transforms.RandomApply([self.color_jitter], p=0.8),\n",
        "#             transforms.RandomGrayscale(p=0.2)\n",
        "#         ]\n",
        "\n",
        "#         if self.gaussian_blur:\n",
        "#             data_transforms.append(GaussianBlur(kernel_size=int(0.1 * self.input_height, p=0.5)))\n",
        "\n",
        "#         data_transforms.append(transforms.ToTensor())\n",
        "\n",
        "#         if self.normalize:\n",
        "#             data_transforms.append(normalize)\n",
        "\n",
        "#         self.train_transform = transforms.Compose(data_transforms)\n",
        "\n",
        "#     def __call__(self, sample):\n",
        "#         transform = self.train_transform\n",
        "\n",
        "#         xi = transform(sample)\n",
        "#         xj = transform(sample)\n",
        "\n",
        "#         return xi, xj\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck5bHxwuPbat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimCLREvalDataTransform(object):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_height: int = 224,\n",
        "        normalize: Optional[transforms.Normalize] = None\n",
        "    ):\n",
        "\n",
        "      self.input_height = input_height\n",
        "      self.normalize = normalize\n",
        "\n",
        "      data_transforms = [\n",
        "          transforms.Resize(self.input_height),\n",
        "          transforms.ToTensor()\n",
        "      ]\n",
        "\n",
        "      if self.normalize:\n",
        "          data_transforms.append(normalize)\n",
        "      \n",
        "      self.test_transform = transforms.Compose(data_transforms) \n",
        "    def __call__(self, sample):\n",
        "        transform = self.test_transform\n",
        "\n",
        "        xi = transform(sample)\n",
        "        xj = transform(sample)\n",
        "\n",
        "        return xi, xj"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAupNHlP72kn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nt_xent_loss(out_1, out_2, temperature):\n",
        "    out = torch.cat([out_1, out_2],  dim=0)\n",
        "    n_samples = len(out)\n",
        "\n",
        "    # Full similarity matrix\n",
        "    cov = torch.mm(out,  out.t().contiguous())\n",
        "    sim = torch.exp(cov / temperature)\n",
        "\n",
        "    mask = ~torch.eye(n_samples,  device = sim.device).bool()\n",
        "    neg = sim.masked_select(mask).view(n_samples, -1).sum(dim=-1)\n",
        "\n",
        "    # Positive similarity\n",
        "    pos = torch.exp(torch.sum(out_1 * out_2, dim=-1) / temperature)\n",
        "    pos = torch.cat([pos,pos], dim=0)\n",
        "\n",
        "    loss = -torch.log(pos / neg).mean()\n",
        "    return loss"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bThUt3GHhVpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Projection(nn.Module):\n",
        "    def __init__(self,  input_dim = 2048, hidden_dim=2048, output_dim=128):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d ((1, 1)),\n",
        "            Flatten(),\n",
        "            nn.Linear(self.input_dim, self.hidden_dim, bias = True),\n",
        "            nn.BatchNorm1d(self.hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.hidden_dim, self.output_dim,bias = False)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return F.normalize(x, dim=1)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htbU5k3pA2su",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class SimCLR(pl.LightningModule):\n",
        "#         def __init__(self,batch_size,num_samples, world_size = 1, \n",
        "#                      warmup_epochs = 10, max_epochs = 100, lars_lr=0.1, lars_eta = 1e-3, \n",
        "#                      opt_weight_decay = 1e-6, loss_temperature=0.5):\n",
        "#             super().__init__()\n",
        "\n",
        "#             self.save_hyperparameters()\n",
        "\n",
        "#             #Using save_hyperparameters() to avoid these repeated work in below\n",
        "#             # self.batch_size = batch_size\n",
        "#             # self.num_samples = num_....\n",
        "\n",
        "#             self.nt_xent_loss = nt_xent_loss\n",
        "#             self.encoder = resnet50()\n",
        "\n",
        "#             # h -> || -> z\n",
        "#             self.projection = Projection()\n",
        "\n",
        "#             # only needed because of CIFAR-10 images will shrink too much \n",
        "#             self.encoder.conv1 = nn.Conv2d(\n",
        "#                 3, 64,\n",
        "#                 kernel_size = 3,\n",
        "#                 stride = 1,\n",
        "#                 padding = 1,\n",
        "#                 bias = False\n",
        "#             )\n",
        "\n",
        "#             self.maxpool = nn.MaxPool2d(kernel_size=1, stride=1)\n",
        "\n",
        "#         def exclude_from_wt_decay(self, named_params, weight_decay, skip_list=['bias', 'bn']): \n",
        "#             params = []\n",
        "#             excluded_params = []\n",
        "\n",
        "#             for name, param in named_params:\n",
        "#                 if not param.requires_grad:\n",
        "#                     continue\n",
        "#                 elif any(layer_name in name for layer_name in skip_list):\n",
        "#                     excluded_params.append(param)\n",
        "#                 else:\n",
        "#                     params.append(param)\n",
        "\n",
        "#             return [\n",
        "#                 {'params': params, 'weight_decay': weight_decay},\n",
        "#                 {'params': excluded_params, 'weight_decay': 0.}\n",
        "#             ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#         def configure_optimizers(self):\n",
        "#             # TRICK 1 (USE lars + filter weights)\n",
        "#             # exclude certain parameters\n",
        "#             parameters = self.exclude_from_wt_decay(\n",
        "#                 self.named_parameters(),\n",
        "#                 weight_decay = self.hparams.opt_weight_decay\n",
        "#                 # weight_decay = self.hparams.ept_weight_decay\n",
        "#             )\n",
        "\n",
        "#             # optimizer = LARS(parameters, lr=self.hparams.lars_lr, eta=self.hparams.lars_eta)\n",
        "#             optimizer = LARSWrapper(Adam(parameters, lr=self.hparams.lr))\n",
        "\n",
        "#             # Trick 2 (after each step)\n",
        "#             self.hparams.warmup_epochs = self.hparams.warmup_epochs * self.train_iters_per_epoch\n",
        "#             self.hparams.max_epochs = self.hparams.max_epochs * self.train_iters_per_epoch\n",
        "            \n",
        "#             linear_warmup_cosine_decay = LinearWarmupCosineAnnealingLR(\n",
        "#                 optimizer,\n",
        "#                 warmu_epochs = self.hparams.warmup_epochs,\n",
        "#                 warmup_start_lr=0,\n",
        "#                 eta_min=0\n",
        "#             )\n",
        "#             scheduler = {\n",
        "#                 'scheduler': linear_warmup_cosine_decay,\n",
        "#                 'interval': 'step',\n",
        "#                 'frequency': 1\n",
        "#             }\n",
        "            \n",
        "#             return [optimizer], [scheduler]\n",
        "        \n",
        "#         def training_step(self, batch, batch_idx):\n",
        "#             loss = self.shared_step(batch, batch_idx)\n",
        "#             result = pl.TrainResult(minimize=loss)\n",
        "#             result.log('train_loss', loss, on_epoch = True)\n",
        "#             return result\n",
        "\n",
        "#         # if we did the true part in result.log('train_loss', loss, on_epoch=True)\n",
        "#         # losses = []\n",
        "#         # for batch in train_dataloader():\n",
        "#         #     loss = model.training_step(batch, batch_idx)\n",
        "#         #     losses.append(loss)\n",
        "#         #     print('train_loss', loss)\n",
        "\n",
        "#         # Pytorch Lighting has already done this in below for us\n",
        "#         # model.eval()\n",
        "#         # with torch.no_grad():\n",
        "#         #     loss = model.validation_step(batch)\n",
        "#         #         model.train()\n",
        "\n",
        "#         def validation_step(self, batch, batch_idx):\n",
        "#             loss = self.shared_step(batch, batch_idx)\n",
        "\n",
        "#             result = pl.EvalResult(checkpoint_on=loss)\n",
        "#             result.log('avg_val_loss', loss)\n",
        "#             return result\n",
        "\n",
        "#         def shared_step(self, batch, batch_idx):\n",
        "#             (img1, img2), y = batch\n",
        "\n",
        "#             # ENCODE\n",
        "#             # encode -> representations\n",
        "#             # (b, 3, 32, 32) -> (b, 2048, 2, 2)\n",
        "#             h1 = self.encoder(img1)[-1]\n",
        "#             h2 = self.encoder(img2)[-1]\n",
        "\n",
        "#             # PROJECT\n",
        "#             # img -> E -> h -> || -> z\n",
        "#             # (b, 2048, 2, 2) -> (b, 128)\n",
        "#             z1 = self.projection(h1)\n",
        "#             z2 = self.projection(h2)\n",
        "\n",
        "#             loss = self.nt_xnet_loss(z1, z2, self.hparams.loss_temperature)\n",
        "\n",
        "#             return loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8w279X5UJGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimCLR(pl.LightningModule):\n",
        "    def __init__(self,\n",
        "                 batch_size,\n",
        "                 num_samples,\n",
        "                 warmup_epochs=10,\n",
        "                 lr=1e-4,\n",
        "                 opt_weight_decay=1e-6,\n",
        "                 loss_temperature=0.5,\n",
        "                 **kwargs):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            batch_size: the batch size\n",
        "            num_samples: num samples in the dataset\n",
        "            warmup_epochs: epochs to warmup the lr for\n",
        "            lr: the optimizer learning rate\n",
        "            opt_weight_decay: the optimizer weight decay\n",
        "            loss_temperature: the loss temperature\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.nt_xent_loss = nt_xent_loss\n",
        "        self.encoder = self.init_encoder()\n",
        "\n",
        "        # h -> || -> z\n",
        "        self.projection = Projection()\n",
        "\n",
        "    def init_encoder(self):\n",
        "        encoder = resnet50_bn(return_all_feature_maps=False)\n",
        "\n",
        "        # when using cifar10, replace the first conv so image doesn't shrink away\n",
        "        encoder.conv1 = nn.Conv2d(\n",
        "            3, 64,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1,\n",
        "            bias=False\n",
        "        )\n",
        "        return encoder\n",
        "\n",
        "    def exclude_from_wt_decay(self, named_params, weight_decay, skip_list=['bias', 'bn']):\n",
        "        params = []\n",
        "        excluded_params = []\n",
        "\n",
        "        for name, param in named_params:\n",
        "            if not param.requires_grad:\n",
        "                continue\n",
        "            elif any(layer_name in name for layer_name in skip_list):\n",
        "                excluded_params.append(param)\n",
        "            else:\n",
        "                params.append(param)\n",
        "\n",
        "        return [\n",
        "            {'params': params, 'weight_decay': weight_decay},\n",
        "            {'params': excluded_params, 'weight_decay': 0.}\n",
        "        ]\n",
        "\n",
        "    def setup(self, stage):\n",
        "        global_batch_size = self.trainer.world_size * self.hparams.batch_size\n",
        "        self.train_iters_per_epoch = self.hparams.num_samples // global_batch_size\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # TRICK 1 (Use lars + filter weights)\n",
        "        # exclude certain parameters\n",
        "        parameters = self.exclude_from_wt_decay(\n",
        "            self.named_parameters(),\n",
        "            weight_decay=self.hparams.opt_weight_decay\n",
        "        )\n",
        "\n",
        "        optimizer = LARSWrapper(Adam(parameters, lr=self.hparams.lr))\n",
        "\n",
        "        # Trick 2 (after each step)\n",
        "        self.hparams.warmup_epochs = self.hparams.warmup_epochs * self.train_iters_per_epoch\n",
        "        max_epochs = self.trainer.max_epochs * self.train_iters_per_epoch\n",
        "\n",
        "        linear_warmup_cosine_decay = LinearWarmupCosineAnnealingLR(\n",
        "            optimizer,\n",
        "            warmup_epochs=self.hparams.warmup_epochs,\n",
        "            max_epochs=max_epochs,\n",
        "            warmup_start_lr=0,\n",
        "            eta_min=0\n",
        "        )\n",
        "\n",
        "        scheduler = {\n",
        "            'scheduler': linear_warmup_cosine_decay,\n",
        "            'interval': 'step',\n",
        "            'frequency': 1\n",
        "        }\n",
        "\n",
        "        return [optimizer], [scheduler]\n",
        "\n",
        "    def forward(self, x):\n",
        "        if isinstance(x, list):\n",
        "            x = x[0]\n",
        "\n",
        "        result = self.encoder(x)\n",
        "        if isinstance(result, list):\n",
        "            result = result[-1]\n",
        "        return result\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss = self.shared_step(batch, batch_idx)\n",
        "\n",
        "        result = pl.TrainResult(minimize=loss)\n",
        "        result.log('train_loss', loss, on_epoch=True)\n",
        "        return result\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss = self.shared_step(batch, batch_idx)\n",
        "\n",
        "        result = pl.EvalResult(checkpoint_on=loss)\n",
        "        result.log('avg_val_loss', loss)\n",
        "        return result\n",
        "\n",
        "    def shared_step(self, batch, batch_idx):\n",
        "        (img1, img2), y = batch\n",
        "\n",
        "        # ENCODE\n",
        "        # encode -> representations\n",
        "        # (b, 3, 32, 32) -> (b, 2048, 2, 2)\n",
        "        h1 = self.encoder(img1)\n",
        "        h2 = self.encoder(img2)\n",
        "\n",
        "        # the bolts resnets return a list of feature maps\n",
        "        if isinstance(h1, list):\n",
        "            h1 = h1[-1]\n",
        "            h2 = h2[-1]\n",
        "\n",
        "        # PROJECT\n",
        "        # img -> E -> h -> || -> z\n",
        "        # (b, 2048, 2, 2) -> (b, 128)\n",
        "        z1 = self.projection(h1)\n",
        "        z2 = self.projection(h2)\n",
        "\n",
        "        loss = self.nt_xent_loss(z1, z2, self.hparams.loss_temperature)\n",
        "\n",
        "        return loss"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSeIZy-uw8i5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimCLRTrainDataTransform(object):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_height: int = 224,\n",
        "        gaussian_blur: bool = False,\n",
        "        jitter_strength: float = 1.,\n",
        "        normalize: Optional[transforms.Normalize] = None\n",
        "    ) -> None:\n",
        "\n",
        "        self.jitter_strength = jitter_strength\n",
        "        self.input_height = input_height\n",
        "        self.gaussian_blur = gaussian_blur\n",
        "        self.normalize = normalize\n",
        "\n",
        "        #jitter transform\n",
        "        self.color_jitter = transforms.ColorJitter(\n",
        "            0.8 * self.jitter_strength,\n",
        "            0.8 * self.jitter_strength,\n",
        "            0.8 * self.jitter_strength,\n",
        "            0.2 * self.jitter_strength\n",
        "        )\n",
        "\n",
        "        data_transforms = [\n",
        "          transforms.RandomResizedCrop(size=self.input_height),\n",
        "          transforms.RandomHorizontalFlip(p=0.5),\n",
        "          transforms.RandomApply([self.color_jitter], p = 0.8),\n",
        "          transforms.RandomGrayscale(p=0.2)\n",
        "        ]\n",
        "        if self.gaussian_blur:\n",
        "            data_transforms.append(GaussianBlur(kernel_size=int(0.1 * self.input_height, p=0.5)))\n",
        "\n",
        "        data_transforms.append(transforms.ToTensor())\n",
        "\n",
        "        if self.normalize:\n",
        "            data_transforms.append(normalize)\n",
        "\n",
        "        self.train_transform = transforms.Compose(data_transforms)\n",
        "\n",
        "    def __call__(self, sample):\n",
        "      transform = self.train_transform\n",
        "      xi = transform(sample)\n",
        "      xj = transform(sample)\n",
        "\n",
        "      return xi, xj "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdgQZuP0F0Bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import os\n",
        "\n",
        "# # callbacks\n",
        "# lr_logger = LearningRateLogger\n",
        "# callbacks = [lr_logger]\n",
        "\n",
        "# cifar_height = 32\n",
        "# batch_size = 8   #32GB ram use 1024\n",
        "\n",
        "# dm = CIFAR10DataModule(os.getcwd(), num_workers=8, batch_size=batch_size)\n",
        "# dm.train_transforms = SimCLRTrainDataTransform(cifar_height)\n",
        "# dm.val_transforms = SimCLREvalDataTransform(cifar_height)\n",
        "# dm.test_transforms = SimCLREvalDataTransform(cifar_height)\n",
        "\n",
        "# # materialize data\n",
        "# dm.prepare_data()\n",
        "# dm.setup()\n",
        "\n",
        "# train_samples = len(dm.train_dataloader()) * batch_size\n",
        "\n",
        "# # init model\n",
        "# mode = SimCLR(batch_size, num_samples = train_samples)\n",
        "\n",
        "# # now train\n",
        "# trainer = pl.Trainer(callbacks=callbacks, progress_bar_refresh_rate=10, gpus=1, precision=16)   #, sync_batchnorm=True\n",
        "\n",
        "\n",
        "# # fit!\n",
        "# trainer.fit(model, dm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KGhMkQqURpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pl_bolts.models.self_supervised.resnets import resnet50_bn"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_V7dWijR1if",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42fd1231-d48b-45a0-fb2c-f4202934f3bd"
      },
      "source": [
        "import os\n",
        "from pl_bolts.callbacks.self_supervised import SSLOnlineEvaluator\n",
        "\n",
        "# init callbacks\n",
        "def to_device(batch, device):\n",
        "    (img1, _), y = batch\n",
        "    img1 = img1.to(device)\n",
        "    y = y.to(device)\n",
        "    return img1, y\n",
        "\n",
        "online_finetuner = SSLOnlineEvaluator(z_dim=2048 * 2 * 2, num_classes = 10)\n",
        "online_finetuner.to_device = to_device\n",
        "\n",
        "lr_logger = LearningRateLogger()\n",
        "\n",
        "callbacks = [online_finetuner, lr_logger]\n",
        "\n",
        "# pick data\n",
        "cifar_height = 32\n",
        "batch_size = 8\n",
        "num_samples = 32\n",
        "\n",
        "# init data\n",
        "dm = CIFAR10DataModule(os.getcwd(), num_workers=0, batch_size=batch_size)\n",
        "dm.train_transforms = SimCLRTrainDataTransform(cifar_height)\n",
        "dm.val_transforms = SimCLREvalDataTransform(cifar_height)\n",
        "\n",
        "# realize the data\n",
        "dm.prepare_data()\n",
        "dm.setup()\n",
        "\n",
        "train_samples = len(dm.train_dataloader())\n",
        "\n",
        "model = SimCLR(batch_size=batch_size, num_samples=train_samples)\n",
        "trainer = pl.Trainer(callbacks=callbacks, progress_bar_refresh_rate=10, gpus=1)\n",
        "trainer.fit(model, dm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
            "  warnings.warn(*args, **kwargs)\n",
            "\n",
            "  | Name                 | Type         | Params\n",
            "------------------------------------------------------\n",
            "0 | encoder              | ResNet       | 25 M  \n",
            "1 | projection           | Projection   | 4 M   \n",
            "2 | non_linear_evaluator | SSLEvaluator | 8 M   \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "390013ba70734d3892f74c4df9932ac6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a6e0c9ba0d949c9bc5a4b87870347f0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d966d0cc01094b3691550447cdaeb0df",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de2a88fc1cc04e3aaaab42c6918e2d08",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2dc16cfac02445c7b62b2e84d9e05c61",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2580c63b4ad349988eef6c9f76f5c9d3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a74fbd9935e45b8a7ab4476250ccf74",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49faec56e58c40939ebeb98480074a88",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eafeb7c7c2554264b49fc1ff7e57e90e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "979a7e575b744068841c0975fff34485",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e11c4b9232aa4d17b2facd971811c857",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33d330bb31e24eb1ba24fcc7db258a24",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea331c5ec62a4dd0b6b8649f9aae01d8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a64e51e5194485a8a0a0002849a566d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aeafee3e132f467e886602a2fedb0930",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ad1b6365acd484bbc68412a63cd2b61",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6408d62f614745b09570b864641266f6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eaa8f36c03314d3793a8358bd732e019",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a177f89bf5314071bffb1e8c7de2ba12",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c195bae76b54346a3e8341cc483c17c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0cb1eec6a6284486a9b9397e0bbc8a4f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca17e38b89c446d8a8b6f57cd06e9889",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5804135c3a943b3877dce467f8cbe91",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07689259ec0f4187b9eb0b8530493cad",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e013a7241b214356a88f796e1665b4bc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1342c058c8a4fbd84b93b46f8e4e2b9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85fb1b70b285401e80bc88914fc4222f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb5ad0a3d61e4ea2a57b32778cc775ba",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe1bae6bf8f24fbf9b0e740f87c2da1d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96af30396abe47959baf02b9898f2832",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "286a714c6713488fa2de6c39fbd07587",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94e65a42a5794776b54ae6c10f7f90dc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4b1a83cbf8142d7b7c898baa9de02cd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7019cfa0a9544edbc4943bb2dea56bb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ee91f3dba0f44b5b1ac868fd4fa1e7f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8od6jTx6O5Lh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}